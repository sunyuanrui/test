#### 摘要

本篇文章介绍了使用CNN对图像数据进行学习来比较图像块的相似性。该方法在一些问题和基准数据集上有更好的效果。

#### 1.介绍

图像块的比较是很多计算机视觉和图像分析的基本任务之一，不论是低级别任务，比如运动结构、构建全景图。还是高级别任务，对象识别，图像检索等。

决定两个图像块是否相对应的问题，是非常具有挑战性的，因为存在很多影响图像最终外观的因素，包括视点的变化、场景整体照明的变化、遮挡、相机设置的差异等，在过去，使用了很多手工设计的特征描述，比如SIFT。然而，这种手工设计的描述可能无法以最佳方式考虑所有上述确定补丁外观的因素。我们现在有现成的图像块匹配数据集，如何使用数据集学习一个相似性函数。

本文的主要贡献：1、我们直接从图像数据中学习（即没有任何手动设计的特征）一般的相似性函数，并且不受各种类型的转换和影响，比如光照和宽基线。2、探索并提出了各种适合表示这种功能的神经网络模型，同时突出显示提高了性能的网络架构。3、在一些问题及基准数据集上性能更好，优于手工设计的特征描述，比如SIFT、DAISY等。

#### 2.相关工作

#### 3.架构

神经网络的输入是一对图像块（本文大小64x64），不限制图像的通道数，本文输入的是灰度图。

本文介绍了三种网络架构，2-channel, Siamese, Pseudo-siamese。区别在于是否首先选择计算每个图像块的的特征描述符，还是选择跳过与描述符计算相关的部分并直接进行相似性估计。

##### 3.1基础模型

（青色 = Conv+ReLU, 紫色 = max pooling, 黄色 = fully connected layer (ReLU exists between fully connected layers as well））

**Siamese网络**：类似于计算特征描述，网络有两个分支，具有完全相同的体系结构和相同的权重集合。每个分支有一个图像作为输入，分支输出连接在一起，包含两个全连接层，（每层有512个隐藏单元）由RELU激活层分隔开。两个分支网络学习特征描述，顶部网络为相似性函数，（甚至可以用距离函数替代，比如$$l_2$$），网络本质上每个分支就相当于一个特征提取的过程，然后最后一层就相当计算特征向量相似度的函数一样。

![Siamese网络结构](https://img-blog.csdn.net/20151204201146814?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)

**Pseudo-siamese网络**：该网络的复杂度介于Siamese网络于2-channel之间。具体来说，两个分支的权重是不共享的，增加了可以训练的参数，更加灵活并且测试效率与Siamese网络一样。

**2-channel网络**：跳过了分支的显式的特征提取过程，而是直接学习相似度评价函数。把输入的两张灰度图片看成是一张双通道的图片一样。

![2-channel网络](https://img-blog.csdn.net/20151204202905335?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)

输出为一层全连接层，只有一个输出。直接表示两张图片的相似度。直接用双通道图片进行训练会比较快，但是测试会比较麻烦，因为需要把每两张图片组合一起测试。用2-channel的方法，经过了第一次的卷积后，两张输入图片就不分你我了。而Siamese网络是到了最后全连接的时候，两张图片的相关神经元才联系在一起。

##### 3.2其他模型

**Deep network**：大卷积核使用3*3卷积核及RELU激活函数分离，具有更高的非线性，使得决策网络更具有辨识性。

**Central-surround two-stream network**：把图片64x64的图片，处理成两张32x32图片，然后再输入网络，一张是是通过以图片中心，进行裁剪出32x32的图片，另一张是对原图进行下采样得到32x32图片。

![Siamese和Central-surround two-stream network结合](https://img-blog.csdn.net/20151204204321135?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)

原因，多分辨率信息在提高图像匹配性能方面是非常重要的，另外相当于将焦点放在了图像块的中心，减少了对周边像素的关注，本质上允许外围像素具有更大的方差。另外，总输入维数减少了两倍，训练更快。

**Spatial pyramid pooling (SPP) network for comparing patches**：网络要求输入补丁的固定大小为64x64。这个要求来自网络的最后一个卷积层的输出需要具有预定义的维度。使用空间金字塔池化解决输入图像尺度不一的问题。

![Siamese和SPP结合](https://img-blog.csdn.net/20151204210638256?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)

#### 4.学习

**优化**：强监督学习，采用了如下损失函数：

![损失函数](https://img-blog.csdn.net/20151204211046442?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)

结合了L2正则项和hinge-loss，w是神经网络的权重，$o_i^{net}$ 是第i个训练样本的网络输出，$y_i$ ={-1,1}，表示非匹配和匹配对。

参数训练更新方法采用ASGD，其学习率恒为1.0，动量参数选择0.9，然后权重衰减大小0.0005，训练的min-batch大小选择128。权重采用随机初始化方法，均从头开始训练。

**数据增强和预处理**： 为了克服过拟合问题，我们通过水平和垂直翻转两个补丁来增加训练数据，并旋转到90,180,270度，训练2天。

#### 5实验

##### 5.1 基准数据集

1、基于2-channel的模型在所有模型中表现出最佳性能，（如2ch, 2ch-deep, 2ch-2stream），2ch-2stream最佳，2ch-deep次之，说明匹配过程中多分辨率信息的重要性以及网络深度也有帮助。

2、siam-2stream比siam网络表现更好，再次验证多分辨率信息的重要性，此外，pseudo-siam比siam网络好。

3、使用$l_2$距离替换决策网络，siam-2stream-l2效果最好。

##### 5.2 宽基线立体评估

使用神经网络模型的光度成本photometric cost优于手工设计的特征，比如DAISY。

##### 5.3 局部描述符性能评估

使用MSER区域检测，优于手工设计的特征，如SIFT，另外siam-SPP-l2，带有Spp层效果明显。

#### 6.结论

在这些架构中，基于2-channel的模型显然在结果方面更胜一筹。多分辨率信息对于提升性能有着很重要的作用。

